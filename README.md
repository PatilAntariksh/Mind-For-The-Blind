**Project Overview**
"Mind-For-The-Blind" is a help assist technology application made for the visually impaired individuals by providing help in the overall navigation , currency detection, and AI-powered conversational support. The mobile application integrates machine learning, natural language processing, and secure video communication to enhance the daily lives of blind users. The system consists of a mobile application, backend API, AI assistant, currency detection module, video call functionality, and cloud database authentication. Our major goal is to to empower visually impaired individuals to navigate their daily lives independently by providing an accessible, intuitive, and secure mobile application that assists with currency identification, Real time safe navigation, and voice-based guidance.

Project vision
To empower visually impaired individuals to navigate their daily lives independently by providing an accessible, intuitive, and secure mobile application that assists with currency identification, Real time safe navigation, and voice-based guidance. The vision of "Mind-For-The-Blind" is to create an accessible solution for the visually impaired that significantly lowers their dependency on their helpers and quality of life is improved.

We want to develop a wearable headset equipped with a high-definition camera that seamlessly connects with the mobile application. This headset will allow visually impaired users to experience real-time object detection, navigation support, and AI-powered assistance hands-free. The camera will continuously analyze surroundings, recognize objects, read text, and provide real-time audio feedback directly to the user. Additionally, the system will integrate with cloud-based AI models to offer instantaneous scene interpretation, improving mobility and awareness in various environments. This ambitious feature aims to create a fully immersive, real-time guidance system, setting a new benchmark for assistive technology. We also plant to add a signal detection model to help the visually impaired person cross the road.

Project Scope
Scope of the Project:
Currency Detection:
Implement ML models to detect and identify currency denominations from user-scanned images.

Video-Call-Based Navigation:
Develop a secure video-call feature to connect users with volunteers/navigators for real-time assistance.

Voice-Based UI Guidance:
Integrate voice-based navigation and feedback to help users interact with the app.

AI-Powered Personal Assistant:
Provide an intelligent voice assistant to answer user queries and guide them.

Security Features:
Ensure secure access and encryption for video calls and user data.

Cross-Platform Development:
Use the Flutter framework to develop the app for both Android and iOS platforms.

Roles
Project Lead: Antariksh Sanjay Patil
Project Manager: Harsh Singh
Architect / Tech lead: Krinal Akbari, Antariksh Sanjay Patil
Developers: Antariksh Sanjay Patil, Krinal Akbari, Swaraj Bhalerao, Khushi Suman
DevOps / Automation: Krinal Akbari, Akhil G
Test Engineer: Swaraj Bhalerao
UX Designer: Khushi Suman, Akhil G
Requirements Engineer: Harsh Singh, Swaraj Bhalerao